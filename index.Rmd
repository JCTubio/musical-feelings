---
title: "Happiness perception vs Valence"
output:
  flexdashboard::flex_dashboard:
    orientation: rows
    storyboard: true
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(car)
library(gvlma)
library(plotly)
library(gvlma)
music_ds <- readxl::read_excel('Music_ds.xlsx')

#Select only participants who finished the questionnaire with no problems
cln_music <- music_ds%>%
  subset(Status==0 & Finished == 1)

#Select only participants that took more than 4 minutes to do the questionnaire
cln_music <- cln_music%>%
  subset(`Duration (in seconds)`>240)

#Dataset with important variables
stats_ds <- cln_music%>%
  select(-c(Status:RecordedDate),-Q21)

#Change var names to delete spaces
colnames(stats_ds)[2:16] <- tolower(gsub('g ','g',colnames(stats_ds)[2:16]))

###Change the order of Song_n scores so higher score = happier song###

my_fun <- function(x){8-x}
new_cols<- t(apply(stats_ds[,2:16],1,my_fun))

stats_ds <- cbind(stats_ds,new_cols)

stats_ds <- stats_ds%>%
  select(-(2:16))

## hypothesis 1
#get songs valence
vlncs <- data.frame(song = colnames(stats_ds)[20:34], valence = c(0.934,0.892,0.88,0.736,0.598,0.537,0.418,0.262,0.637,0.109,0.130,0.403,0.473,0.531,0.354))

#get songs names
song_names <- data.frame(id = colnames(stats_ds)[20:34], name = c("cold heart – pnau remix", "industry baby (feat. jack harlow)", "ibiza", "amsterdam", "le bled", "bad habits", "hard to say goodbye", "where are you now", "do it do it", "moth to a flame (with the weeknd)", "easy on me", "thunder", "ghost", "heat waves", "remember (and david guetta)"), valence = c(0.934,0.892,0.88,0.736,0.598,0.537,0.418,0.262,0.637,0.109,0.130,0.403,0.473,0.531,0.354))

  #put data in the right format
reg_ds <- stats_ds%>%
  pivot_longer(song1:song15)%>%
  select(song = name, hppy = value,ResponseId)%>%
  inner_join(vlncs)

part <- unique(reg_ds$ResponseId)
songs <- unique(reg_ds$song)
stand_ds <- data.frame(song = NA, hppy = NA, valence = NA, scaled_valence = NA, z_hppy = NA, ResponseId = NA)

for(i in 1:length(part)){
  this_part <- reg_ds%>%
    subset(ResponseId == part[i])%>%
    mutate(z_hppy = (hppy-mean(hppy))/sd(hppy))%>%
    mutate(scaled_valence = valence * 7) #Since valence is measured in a 0-1 scale, multiplying it by 7 we can compare the values with perceived happiness easily
  stand_ds <- stand_ds%>%
    add_row(this_part)
  ifelse(i == length(part),stand_ds <- stand_ds[-1,],NA)
#fit the model just so i can check the assumptions
fit <- lm(valence ~ z_hppy,stand_ds)

## hypothesis 2
#get sophistication scores
sphst <- stats_ds%>%
  select(ResponseId,Q16_1:Q19)%>%
  mutate(Q16_7 = 8 - Q16_7)%>% #correcting the contraindicative items
  mutate(Q16_9 = 8 - Q16_9)%>%
  mutate(Q16_11 = 8 - Q16_11)%>%
  mutate(Q16_13 = 8 - Q16_13)%>%
  mutate(Q16_14 = 8 - Q16_14)
sphst <- sphst%>%
  mutate(sophi = rowSums(sphst[,2:19]))%>%
  select(ResponseId,sophi)
  
  #get dataset 
mod_ds <- stats_ds%>%
  pivot_longer(song1:song15)%>%
  select(ResponseId,song = name, hppy = value)%>%
  inner_join(vlncs)%>%
  inner_join(sphst)%>%
  select(-hppy,-valence)%>%
  inner_join(stand_ds, by = c('song','ResponseId'))

 #fit model to check assumption
X <- mod_ds$hppy
Z <- mod_ds$sophi
Y <- mod_ds$valence
X <- c(scale(X, center = T, scale = F))
sophistication <- c(scale(Z, center = T, scale = F))
library(gvlma)
fitMod <- lm(Y ~ X + sophistication + X*sophistication) 
}
## hypothesis 3
#make the three different sophistication groups
low <- sort(sphst$sophi)[1:(length(sphst$sophi)*(1/3))]
mid <- sort(sphst$sophi)[(length(sphst$sophi)*(1/3)+1):(length(sphst$sophi)*(2/3))]
high <- sort(sphst$sophi)[(length(sphst$sophi)*(2/3)+1):(length(sphst$sophi))]

#make data set 
var_ds <- stats_ds%>%
  pivot_longer(song1:song15)%>%
  select(ResponseId,song = name, hppy = value)%>%
  inner_join(vlncs)%>%
  inner_join(sphst)%>%
  mutate(grp = ifelse(sophi %in% low, 1,2))%>%
  mutate(grp = ifelse(sophi %in% high,3,grp))%>%
  mutate(grp = as.factor(grp))
```

Hypothesis 1
=======================================================================

Row {data-height=650}
-------------------------------------

### Hypothesis: Perceived happiness can predict songs valence
    
```{r}
reg_ds%>% 
  ggplot(aes(factor(hppy), valence))+ 
  geom_boxplot(fill = '#1DB954')+
  xlab('Happiness rating')+
  ylab('Song valence')+
  labs(title = 'Songs rated as happier tend to have a higher valence',
       subtitle = 'Distribution of valences for songs rated at different happiness level')+
  theme_minimal()+
  theme(plot.title = element_text(face = 2),
        panel.grid.major.x = element_blank())
```

Row {.tabset .tabset-fade}
-------------------------------------

### Resid
```{r, results='hide'}
#norality of the residuals
qqPlot(fit)
```

### Homoscedasticity
```{r}
#homoscedasticity
plot(fitted(fit),resid(fit))
lines(c(0.34,0.7),c(0,0), lty = 2,lwd = 2)
```

### Sensitivity
```{r}
#sensitivity
plot(hatvalues(fit))
```

### Fitting the model
The model seems to fit adequately well. 
Both the intercept and the slope coefficients are significant and the R2 = 0.1211. This can be interpreted as happiness score being able to explain 12% of the variance in the song's valence. 
```{r}
fit <- lm(valence ~ z_hppy,stand_ds)
summary(fit)
```

 
Column {.sidebar data-width=300}
-------------------------------------

### Testing the hypothesis
In order to check this prediction, we will perform a simple linear regression in which we try to predict the valence of the song, given the participant's happiness rating. 

### Repeated measures 
Because each participant gave a happiness score for each of the 15 scores, our data set contains what we call 'repeated measures'. Participants may have a tendency to rank songs as being happier or as being sadder, making some of the variance in the happiness scores due to the participant's biases. We want to take this variance out of the analysis and to do so we standardize answers within each participant. Now each participant's answer is a z-score, implying that all participants have a mean answer of 0, and the standard deviation of their answers is 1. There is no more variance due to personal biases!

### Checking the assumptions
Before performing any regressions it is important to check that the data does not violate any of the core assumptions of the analysis. Both of the assumptions were clearly met: there were no significant outliers and the errors were almost normally distributed. The homoscedasticity assumptions was less clearly met, but the violation was considered too subtle to mean any problem for the analysis. 

Hypothesis 2
=======================================================================

Row {.tabset data-height=650}
-------------------------------------

### Hypothesis: The relationship between happiness and valence is moderated by music sophistication
    
```{r}


low <- sort(sphst$sophi)[1:(length(sphst$sophi)*(1/3))]
mid <- sort(sphst$sophi)[(length(sphst$sophi)*(1/3)+1):(length(sphst$sophi)*(2/3))]
high <- sort(sphst$sophi)[(length(sphst$sophi)*(2/3)+1):(length(sphst$sophi))]

#make data set 
plot_ds <- stats_ds%>%
  pivot_longer(song1:song15)%>%
  select(ResponseId,song = name, hppy = value)%>%
  inner_join(vlncs)%>%
  inner_join(sphst)%>%
  mutate(grp = ifelse(sophi %in% low, 1,2))%>%
  mutate(grp = ifelse(sophi %in% high,3,grp))%>%
  mutate(grp = as.factor(grp))

levels(plot_ds$grp) <- c('Low','Mid','High')

ggplot(plot_ds,aes(x=factor(hppy),y=valence,fill = grp))+
  geom_boxplot()+
  facet_grid(.~grp)+
  xlab(label = 'Happiness scores')+
  ylab(label = ifelse(i == 1,'Valence',''))+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))+
  theme(legend.position =  'none',
        panel.grid.major.x = element_blank())+
  scale_fill_manual(values = c('Low' = "#c5f6d6",'Mid' = "#83eca7",'High' = "#1db954"))+
  labs(title = 'Sophistication has no moderation effect', subtitle = 'Valence distributions at each level of happiness by sophistication levels')
```
 
Row {.tabset}
-------------------------------------
### Setup
To check this prediction we perform a moderation analysis. We keep the standardized version of the happiness scores because of the same reasons exposed in the simple linear regression. 

### Checking extra assumptions
Performing a moderation analysis implies entering the domains of the multiple linear regression (i.e. now there os more than one predictor). This means that the multicollinearity between predictors must be checked. To do so we look at the VIF values of the two predictors used, and there seems to be no multicollinearity at all.

```{r}
library(car)
vif(fitMod)

```

### Fitting the model
The model points at the interaction term being not significant and R2 = 0.1043. This points at our prediction not being met: the interaction is not significant and including this interaction term into the regression 

```{r}
    #Center data (this is not the same as the standardization process we did before)
X <- mod_ds$hppy
Z <- mod_ds$sophi
Y <- mod_ds$valence

X <- c(scale(X, center = T, scale = F))
sophistication <- c(scale(Z, center = T, scale = F))

    #Fit model
library(gvlma)
fitMod <- lm(Y ~ X + sophistication + X*sophistication) 
summary(fitMod)
```

### Analysis and conclusion
Although the fit statistics already point at our prediction being not supported by the data, we can explore it visually. To do so we plot the valence distribution of songs at each level of happiness, for three different sophistication levels. If there was a moderation effect we would expect the direction of the relationship to change significantly in at least one of the three sophistication levels. Nevertheless, in all three plots, the relationship between valence and happiness seems identical.

Hypothesis 3
=======================================================================

Row {.tabset data-height=650}
-------------------------------------

### Hypothesis: The variance in perceived happiness scores is lower among highly sophisticated participants
```{r}
#calculate levene's test and make plots

songs <- unique(var_ds$song)
plot <- list()

for(i in 1:15){
  song <- var_ds%>%
    subset(song == songs[i])
  lev_p <- p.adjust(car::leveneTest(song$hppy,song$grp)$`Pr(>F)`[1],'bonferroni',15) #we correct for multiple testing
  plot[[i]] <- ggplot(song,aes(grp,hppy,fill = grp))+
    geom_boxplot()+  
    ggtitle(paste(c('   Song ',i),collapse = ''))+
    scale_x_discrete(labels = c('low','mid','high'))+
    xlab(ifelse(i %in% 11:15,'sophistication',''))+
    ylab(ifelse(i %in% c(1,6,11),'happiness',''))+
    theme(plot.title = element_text(face="bold"))+
    scale_fill_manual(values = c('1' = "#c5f6d6",
                                 '2' = "#83eca7",
                                 '3' = "#1db954"))+
    theme_minimal()+
    theme(legend.position = 'none')+
    scale_y_continuous(breaks = seq(1,7,by = 1))+
    ylim(1,7)
  }

gridExtra::grid.arrange(plot[[1]],plot[[2]],plot[[3]],plot[[4]],plot[[5]],plot[[6]],plot[[7]],
                        plot[[8]],plot[[9]],plot[[10]],plot[[11]],plot[[12]],plot[[13]],
                        plot[[14]],plot[[15]],nrow = 3)
```

### Sophistication spread
```{r}


var_ds%>%
  select(ResponseId,sophi,grp)%>%
  unique()%>%
  ggplot(aes(x = sophi,fill = grp))+
  geom_histogram(color = 'black',binwidth = 3,center =1.5)+
  scale_fill_manual(values = c('1' = "#c5f6d6",
                                 '2' = "#83eca7",
                                 '3' = "#1db954"),
                      labels = c('Low','Mid','High'))+
  labs(title = 'Sample shows spread enough sophistication scores',
       subtitle = 'Distribution of sophistication scores',
       fill = 'Group')+
  xlab('Sophistication')+
  ylab('Frequency')+
  theme_minimal()+
  scale_x_continuous(breaks = seq(40,110,10))+
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        plot.title = element_text(face = 2),
        axis.title.x = element_text(margin = margin(t=5)),
        axis.title.y = element_text(margin = margin(r=10)))

        

  




```

Row {.tabset}
-------------------------------------

### Levene's test
To check this prediction we use the Levene's test. In doing so we compare the happiness scores variance of the 'low','mid' and 'high' sophistication group for each of the 15 songs. If the test shows a significant p-value, at least one of the groups has a different variance than the others. To see exactly what group has this different variance and visualize the data, we plot the happiness score distribution for each sophistication group using a boxplot. If our prediction was supported by the data, then the dark green box (i.e. variance of the highly sophisticated participants) would be systematically smaller than the lighter green boxes (i.e. variance of the 'mid' and 'low' participants). As a final note, Levene's test's p-values are corrected for multiplied testing using Bonferroni's correction.

### Analysis
As we can see from the corrected Levene's tests p-value, none of the songs groups have different variances. From visual inspection we can also see that the dark green box does not tend to be smaller than the other two.

### Considerations
It could be the case that our sample has a low sophistication in general. This would mean that our 'high' group still has a low sophistication in absolute terms, and thus we are not able to infer anything about highly sophisticated people and variance in happiness scores. To check this we plot the music sophistication distribution in our sample. We can see here nevertheless, that sophistication levels are sufficiently spread and we can consider our sample representative enough.

Background {data-orientation=columns}
=======================================================================

Column
-----------------------------------------------------------------------

### Introduction
The demand for music has grown to become an important aspect of many peoples’ everyday life (Fuentes et al., 2019). Especially, the mode of music listening has shifted from only actively listening to music from time to time, to the soundtracking of daily activities. People accompany various activities with music, and it becomes an affective-practical resource. Several studies have focused on Music Emotion Recognition (MER) (Aljanaki et al. 2014). It focuses mostly on two dimensions: “valence (positive vs. negative) and arousal (quiet vs. energetic). However, the perfect MER model has not yet been found, as subjective and objective views on music often differ greatly (REF). 

### Research Question
This study will try to understand the measurement of valence and whether subjective and objective valence differs as much in our sample. Additionally, many studies have shown that musical sophistication has an effect on the relationship between objective and subjective musical perception (REF). We will examine whether the level of expertise in music will impact musical perception in the context of valence, leading to the following research question:

**To what extent does objective valence judgement predict subjective happiness ratings and to what extent is this relationship moderated by music sophistication?**


### Data cleaning
The original data set contained 103 responses, but some had to be dropped. 
21 participants did not finish the questionnaire and were thus removed from the data set. Furthermore, four participants took less than four minutes to complete the questionnaire. 
This was considered unreasonably low and so these responses were also removed from the data set. After this cleaning process, the data set contained 78 responses. 

Column {.tabset .tabset-fade}
-----------------------------------------------------------------------

### Playlist
```{r}
knitr::kable(song_names)
```

